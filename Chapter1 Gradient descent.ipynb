{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87afc1fe",
   "metadata": {},
   "source": [
    "## Gradient descent 梯度下降法\n",
    "\n",
    "### 基本思路\n",
    "\n",
    "- 输入：目标函数f(x)，梯度函数$g(x)=\\nabla f(x)$. 精度$\\epsilon$, 步长 $\\eta$\n",
    "- 输出：$f(x)$的极小值\n",
    "---\n",
    "- 1 初始值$x^{(0)} \\in R^{(n)}$，置$k=0$\n",
    "- 2 计算$f(x^{k})$\n",
    "- 3 计算梯度$g_k = g(x^{k}) $，当$||g_k|| < \\varepsilon$时，停止迭代\n",
    "- 4 当$||g_k|| >= \\varepsilon$时，步进$x^{k+1} = x^{k} - \\eta * g_k$\n",
    "- 5 重复2，3，4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332044f",
   "metadata": {},
   "source": [
    "# 一维梯度下降法\n",
    "\n",
    "$$\n",
    "f(x) = x^2+1 \\\\\n",
    "f'(x) = 2 * x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8509180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(x):\n",
    "    \"\"\"目标函数\"\"\"\n",
    "    return x**2 + 1\n",
    "\n",
    "def grad_target_func(x):\n",
    "    \"\"\"目标函数梯度\"\"\"\n",
    "    return x*2\n",
    "\n",
    "def gradient_descent_algrithm(func, grad, current_x = 0.1, learning_rate = 0.01, precision = 0.01, max_iter = 10):\n",
    "    \"\"\"梯度下降法\"\"\"\n",
    "    for i in range(max_iter):\n",
    "        current_grad = grad(current_x)\n",
    "        if abs(current_grad) < precision:\n",
    "            break\n",
    "            \n",
    "        # update x\n",
    "        current_x = current_x - current_grad * learning_rate\n",
    "        print(\"Number \", i, \", current_x\", current_x, \", f(x): \", func(current_x))\n",
    "    \n",
    "    print(\"当 x = \", current_x, \", f(x)的局部最小值为: \", func(current_x))\n",
    "    \n",
    "    return current_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110bfdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number  0 , current_x 6.0 , f(x):  37.0\n",
      "Number  1 , current_x 3.5999999999999996 , f(x):  13.959999999999997\n",
      "Number  2 , current_x 2.1599999999999997 , f(x):  5.665599999999999\n",
      "Number  3 , current_x 1.2959999999999998 , f(x):  2.6796159999999993\n",
      "Number  4 , current_x 0.7775999999999998 , f(x):  1.6046617599999997\n",
      "Number  5 , current_x 0.46655999999999986 , f(x):  1.2176782335999998\n",
      "Number  6 , current_x 0.2799359999999999 , f(x):  1.078364164096\n",
      "Number  7 , current_x 0.16796159999999993 , f(x):  1.0282110990745599\n",
      "Number  8 , current_x 0.10077695999999996 , f(x):  1.0101559956668416\n",
      "Number  9 , current_x 0.06046617599999997 , f(x):  1.003656158440063\n",
      "当 x =  0.06046617599999997 , f(x)的局部最小值为:  1.003656158440063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06046617599999997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_algrithm(target_func, grad_target_func, current_x= 10, learning_rate= 0.2, precision= 0.01, max_iter= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c258a9",
   "metadata": {},
   "source": [
    "# 二维梯度下降法\n",
    "$$\n",
    "f(x) = -e^{-(x^2+y^2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e165a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def target_func_2d(x, y):\n",
    "    \"\"\"目标函数\"\"\"\n",
    "    return -math.exp(-(x **2 + y **2))\n",
    "\n",
    "def gradient_target_func_2d(x, y):\n",
    "    \"\"\"目标函数梯度2d\"\"\"\n",
    "    deriv_x = 2 * x * math.exp(-(x **2 + y ** 2))\n",
    "    deriv_y = 2 * y * math.exp(-(x **2 + y ** 2))\n",
    "    return deriv_x, deriv_y\n",
    "\n",
    "def gradient_descent_2d(target_func, grad_func, current_x=0.1, current_y=0.1, learning_rate=0.01, precision=0.01, max_iters=20):\n",
    "    \"\"\"二维梯度下降法\"\"\"\n",
    "    for i in range(max_iters):\n",
    "        grad_x, grad_y = grad_func(current_x, current_y)\n",
    "        if np.linalg.norm([grad_x, grad_y], ord=2) < precision:\n",
    "            break\n",
    "        \n",
    "        # update x, y\n",
    "        current_x = current_x - learning_rate * grad_x\n",
    "        current_y = current_y - learning_rate * grad_y\n",
    "        \n",
    "        print(\"Number \", i, \", Current x, y:\", current_x,\" , \", current_y )\n",
    "        \n",
    "    print(\"\\n当 x = \", current_x, \", y = \", current_y , \", f(x)的局部最小值为: \", target_func_2d(current_x, current_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd14fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number  0 , Current x, y: 0.9458658867053549  ,  0.9458658867053549\n",
      "Number  1 , Current x, y: 0.8826544334549  ,  0.8826544334549\n",
      "Number  2 , Current x, y: 0.8083266112542866  ,  0.8083266112542866\n",
      "Number  3 , Current x, y: 0.7208044838602468  ,  0.7208044838602468\n",
      "Number  4 , Current x, y: 0.6188058941145235  ,  0.6188058941145235\n",
      "Number  5 , Current x, y: 0.5037222225452176  ,  0.5037222225452176\n",
      "Number  6 , Current x, y: 0.3824227965845662  ,  0.3824227965845662\n",
      "Number  7 , Current x, y: 0.26824673335239607  ,  0.26824673335239607\n",
      "Number  8 , Current x, y: 0.17532999068693128  ,  0.17532999068693128\n",
      "Number  9 , Current x, y: 0.10937992229287938  ,  0.10937992229287938\n",
      "Number  10 , Current x, y: 0.06666242193107458  ,  0.06666242193107458\n",
      "Number  11 , Current x, y: 0.04023339487195043  ,  0.04023339487195043\n",
      "Number  12 , Current x, y: 0.024192054151996364  ,  0.024192054151996364\n",
      "\n",
      "当 x =  0.024192054151996364 , y =  0.024192054151996364 , f(x)的局部最小值为:  -0.9988301738125699\n"
     ]
    }
   ],
   "source": [
    "gradient_descent_2d(target_func_2d, gradient_target_func_2d, current_x=1, current_y=1, learning_rate=0.2, precision=0.1, max_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1a913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262026a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
