{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ecfcc6",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯法\n",
    "\n",
    "### 朴素贝叶斯通过训练数据集学习联合概率分布$P(X, Y)$.具体学习先验概率$P(Y=c_k)$和条件概率分布$P(X=x|Y = c_k)$。\n",
    "$$\n",
    "P(X, Y) = P(Y) \\cdot P(X|Y)\n",
    "$$\n",
    "先验概率分布\n",
    "$$\n",
    "P(Y = c_k), (k = 1, 2, 3, ...., K)\n",
    "$$\n",
    "条件概率分布\n",
    "$$\n",
    "P(X=x|Y=c_k) = P(X^{(1)} = x^{(1)}, X^{(2)} = x^{(2)}, \\cdots, X^{(n)} = x^{(n)} | Y = c_k)\n",
    "$$\n",
    "于是便学习到联合概率分布$P(X,Y)$. \\\n",
    "**朴素**贝叶斯对条件概率做了**条件独立性**的**强假设**，也因此得名。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X=x|Y=c_k) &= P(X^{(1)} = x^{(1)}, X^{(2)} = x^{(2)}, \\cdots, X^{(n)} = x^{(n)} | Y = c_k)  \\\\ &= \\prod _{j=1}^n P(X^{(j)} = x^{(j)}| Y = c_k)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### 朴素贝叶斯法分类时，通常给定输入$x$，通过学习到的模型计算**后验概率**$P(Y=c_k|X=x)$,后验概率根据贝叶斯定理得：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=c_k|X = x) &= \\frac {P(X = x | Y = c_k)P(Y=c_k)} {\\sum_k P(X=x|Y=c_k)P(Y=c_k)} \\\\\n",
    "&= \\frac {P(Y=c_k) \\prod_j P(X^{(j)} = x{(j)}| Y = c_k)} {\\sum_k P(Y=c_k) \\prod_{j} P(X^{(j)} = x{(j)}| Y = c_k)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "**朴素贝叶斯分类器**可表示为\n",
    "$$\n",
    "y = f(x) = arg \\max_{c_k} \\frac {P(Y=c_k) \\prod_j P(X^{(j)} = x{(j)}| Y = c_k)} {\\sum_k P(Y=c_k) \\prod_{j} P(X^{(j)} = x{(j)}| Y = c_k)} \n",
    "$$\n",
    "\n",
    "### 贝叶斯估计\n",
    "条件概率分布$P(X=x|Y=c_k)$有指数级数量的参数，其估计实际是不可行的。事实上，驾驶$x^{(j)}$可能取值有$S_j$个，$j=1,2,\\cdots,n$,Y的可能取值有$K$个，那么参数个数为$K \\prod_{j=1}^n S_j$。 \\\n",
    "条件概率的贝叶斯估计\n",
    "$$\n",
    "P_{\\lambda}(X^{(j)=a_{jl}}| Y = c_k)= \\frac {\\sum_{i=1}^N I(x_i^{(j)}=a_{il}, y_i = c_k) + \\lambda} {\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda}\n",
    "$$\n",
    "通常对$\\lambda=1$,称为**拉普拉斯平滑**\n",
    "\n",
    "### 后验概率最大化\n",
    "**假设朴素贝叶斯分类器选择0-1损失函数**\n",
    "$$\n",
    "L(Y, f(X))=\n",
    "\\begin{cases}\n",
    "1, &\\mbox{Y $\\not=$ f(X)} \\\\\n",
    "0, &\\mbox{Y = f(X)} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "期望风险函数为：\n",
    "$$\n",
    "R_exp(f) = E(L(Y, f(x))) = E_X \\sum_{k=1}^K [L(c_k, f(X))] P(c_k|X) \\\\\n",
    "\\begin{aligned}\n",
    "f(x) &= arg \\min_{y \\in \\mathrm{y}} \\sum_{k=1}^K [L(c_k, f(X))] P(c_k|X) \\\\\n",
    "&= arg \\min_{y \\in \\mathrm{y}} \\sum_{k=1}^K \\{ [L(c_k, f(X))=1]P(y \\not = c_k|X=x) + [L(c_k, f(X))=0]P(y = c_k|X=x) \\} \\\\\n",
    "&= arg \\min_{y \\in \\mathrm{y}} \\sum_{k=1}^K P(y \\not = c_k|X=x) \\\\\n",
    "&= arg \\min_{y \\in \\mathrm{y}} (1 - P(y = c_k|X=x)) \\\\\n",
    "&= arg \\max_{y \\in \\mathrm{y}} P(y = c_k|X=x)\n",
    "\\end{aligned} \\\\\n",
    "f(x) = arg \\max_{y \\in \\mathrm{y}} P(c_k|X=x)\n",
    "$$\n",
    "\n",
    "### 算法4.1朴素贝叶斯算法(naive Bayes algorithm)\n",
    "输入：训练数据$T=\\{ (x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N) \\}$, 其中$x_i = (x_i^{(1)}, x_i^{(2)},\\cdots, x_i^{(n)})^T$, $x_i^{(j)}$是第i个样本的第j个特征，$x_i^{(j)} \\in {a_{j1}, a_{j2}, \\cdots, a_{jS_j}}$, $a_{jl}$是第j个特征可能取的第$l$个值，$j=1,2,\\cdots,n, l=1,2,\\cdots, S_j, y_i \\in \\{ c_1, c_2, \\cdots, c_K\\}$; 实例$x$  \\\n",
    "输出：实例$x$的分类 \\\n",
    "(1) 计算先验概率和条件概率 \\\n",
    "$$\n",
    "P(Y=c_k) = \\frac {\\sum_{i=1}^N I(y_i=c_k)} {N}, k= 1,2, \\cdots, K \\\\\n",
    "P(X^{(j)}=a_{jl} | Y = c_k) = \\frac {\\sum_{i=1}^N I(x_i^{(j)} = a_{jl}, y_i=c_k)} {\\sum_{i=1}^N I(y_i=c_k)} \\\\\n",
    "j=1,2,\\cdots,n, l=1,2,\\cdots, S_j\n",
    "$$\n",
    "(2)对于给定的实例$x= (x^{(1)}, x^{(2)},\\cdots, x^{(n)})^T$,计算\n",
    "$$\n",
    "P(Y=c_k) \\prod_{j=1}^{n} P(X^{(j)} = x^{(j)} | Y = c_k), k = 1, 2, \\cdots, K\n",
    "$$\n",
    "(3)确定实例x的类\n",
    "$$\n",
    "y = arg\\max_{c_k} P(Y=c_k) \\prod_{j=1}^n P(X^{(j)} = x^{(j)}  | Y = c_k)\n",
    "$$\n",
    "编程时会进行$\\log$运算，对于784个特征(0～1)相乘防止下溢出，而且还可以将相乘变成累加，简化计算\n",
    "$$\n",
    "\\log P(Y=c_k) \\prod_{j=1}^n P(X^{(j)} = x^{(j)}  | Y = c_k) \\\\ = \\log  P(Y=c_k) + \\sum_{j=1}^n \\log P(X^{(j)} = x^{(j)}  | Y = c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5762562",
   "metadata": {},
   "source": [
    "## 例4.1 训练一个朴素贝叶斯分类器，确定$x = (2, S)^T $的类标记$y$。表中$X^{(1)}$和$X^{(2)}$为特征，取值的集合为$A_1 = 1, 2, 3, A_2 = S, M, L,$，Y为类标记，$Y \\in C = \\{1, -1\\}$\n",
    "\n",
    "|var|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|\n",
    "|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n",
    "|$x^{(1)}$|1|1|1|1|1|2|2|2|2|2|3|3|3|3|3|\n",
    "|$x^{(2)}$|S|M|M|S|S|S|M|M|L|L|L|M|M|L|L|\n",
    "|$Y$|-1|-1|1|1|-1|-1|-1|1|1|1|1|1|1|1|-1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b924252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes_train(X_train, y_train):\n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    \n",
    "    # 拉普拉斯平滑\n",
    "    lambda_ = 1\n",
    "    \n",
    "    # label\n",
    "    classType = np.unique(y_train)\n",
    "    # \n",
    "    classNumber = len(classType)\n",
    "    \n",
    "    # 初始化先验概率存放数组\n",
    "    Py = np.zeros((classNumber, 1))\n",
    "    # 对每个类别遍历\n",
    "    for i, labeli in enumerate(classType):\n",
    "        Py[i] = (np.sum(y_train == labeli) + 1) / (len(y_train) + classNumber * 1)\n",
    "    \n",
    "    Py = np.log(Py)\n",
    "    \n",
    "    # 特征维数\n",
    "    featureNumber = 2\n",
    "    \n",
    "    # 计算条件概率分布\n",
    "    Px_y = np.zeros((classNumber, featureNumber, 3))\n",
    "    # 遍历\n",
    "    for i in range(len(y_train)):\n",
    "        label = y_train[i]\n",
    "        # labeli = 0(-1) or 1\n",
    "        labeli = 0 if (label == -1) else label\n",
    "        # 获取当前样本\n",
    "        x = X_train[i]\n",
    "        # 遍历样本每一维度\n",
    "        for j in range(featureNumber):\n",
    "            # \n",
    "            if x[j] == 'S':\n",
    "                temp = 1\n",
    "            elif x[j] == 'M':\n",
    "                temp = 2\n",
    "            elif x[j] == 'L':\n",
    "                temp = 3\n",
    "            else:\n",
    "                temp = x[j]\n",
    "                \n",
    "            temp = int(temp)\n",
    "            \n",
    "            Px_y[labeli][j][temp - 1] += 1\n",
    "        \n",
    "    for label in range(classNumber):\n",
    "        for j in range(featureNumber):\n",
    "            Px_y1 = Px_y[label][j][0]\n",
    "            Px_y2 = Px_y[label][j][1]\n",
    "            Px_y3 = Px_y[label][j][2]\n",
    "\n",
    "            Px_y[label][j][0] = np.log((Px_y1 + 1) / (Px_y1 + Px_y2 + Px_y3 + 3))\n",
    "            Px_y[label][j][1] = np.log((Px_y2 + 1) / (Px_y1 + Px_y2 + Px_y3 + 3))\n",
    "            Px_y[label][j][2] = np.log((Px_y3 + 1) / (Px_y1 + Px_y2 + Px_y3 + 3))\n",
    "                \n",
    "    return Py, Px_y\n",
    "\n",
    "def Predict(Py, Px_y, x):\n",
    "    featureNumber = 2\n",
    "    classNumber = 2\n",
    "    \n",
    "    P = [0] * classNumber\n",
    "    \n",
    "    for i in range(classNumber):\n",
    "        print(\"i = \", i)\n",
    "        sum_ = 0\n",
    "        for j in range(featureNumber):\n",
    "            if x[j] == 'S':\n",
    "                temp = 1\n",
    "            elif x[j] == 'M' :\n",
    "                temp = 2\n",
    "            elif x[j] == 'L':\n",
    "                temp = 3\n",
    "            else:\n",
    "                temp = x[j]\n",
    "                \n",
    "            temp = int(temp)\n",
    "            \n",
    "            sum_ += Px_y[i][j][temp - 1]\n",
    "            print(\"sum = \", sum_)\n",
    "            \n",
    "        P[i] = sum_ + Py[i]\n",
    "        print(Py[i])\n",
    "        print(\"P---------------\", P[i])\n",
    "        \n",
    "    return P.index(max(P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ab0e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8873032 ]\n",
      " [-0.53062825]]  \n",
      "===========\n",
      "  [[[-0.81093022 -1.09861229 -1.5040774 ]\n",
      "  [-0.81093022 -1.09861229 -1.5040774 ]]\n",
      "\n",
      " [[-1.38629436 -1.09861229 -0.87546874]\n",
      "  [-1.79175947 -0.87546874 -0.87546874]]]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.array([\n",
    "    [1, 'S'],\n",
    "    [1, 'M'],\n",
    "    [1, 'M'],\n",
    "    [1, 'S'],\n",
    "    [1, 'S'],\n",
    "    [2, 'S'],\n",
    "    [2, 'M'],\n",
    "    [2, 'M'],\n",
    "    [2, 'L'],\n",
    "    [2, 'L'],\n",
    "    [3, 'L'],\n",
    "    [3, 'M'],\n",
    "    [3, 'M'],\n",
    "    [3, 'L'],\n",
    "    [3, 'L']\n",
    "])\n",
    "\n",
    "y_train = np.array([-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1])\n",
    "\n",
    "Py, Px_y = NaiveBayes_train(X_train= Xtrain, y_train= y_train)\n",
    "print(Py, \" \\n===========\\n \", Px_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e394cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "sum =  -1.0986122886681098\n",
      "sum =  -1.9095425048844386\n",
      "[-0.8873032]\n",
      "P--------------- [-2.7968457]\n",
      "i =  1\n",
      "sum =  -1.0986122886681098\n",
      "sum =  -2.8903717578961645\n",
      "[-0.53062825]\n",
      "P--------------- [-3.42100001]\n",
      "0\n",
      "0\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "X_new = np.array([[2, 'S']])\n",
    "Y_new = np.array([[-1]])\n",
    "\n",
    "errorCount = 0\n",
    "for i in range(len(X_new)):\n",
    "    pred = Predict(Py, Px_y, X_new[i])\n",
    "    print(pred)\n",
    "    testlabeli = 0 if (Y_new[i] == -1) else Y_new[i]\n",
    "    print(testlabeli)\n",
    "    if pred != testlabeli:\n",
    "        errorCount += 1\n",
    "\n",
    "acc = 1 - (errorCount / len(X_new))\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153f8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
